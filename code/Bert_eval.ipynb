{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Bert_eval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-MuxG5NJYDAz"
   },
   "source": [
    "# Use Transfer learning with the multilingual BERT model to classify sentiment of Hebrew Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kbcpILyNYTa4"
   },
   "source": [
    "Source: https://github.com/shudima/notebooks/blob/master/hebrew_snetiment_analysis.ipynb?fbclid=IwAR1XRywUjrhTiHMCpzhxpflRcfawX5n1oA56LvI08TvLizswQK9XXoyvLGA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "Q_enddJNZ9p0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "61c688a0-44dd-45a0-8774-fcbd147fd6a7"
   },
   "source": [
    "\n",
    "\n",
    "!pip install tamnun\n",
    "\n"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Collecting tamnun\n",
      "  Downloading https://files.pythonhosted.org/packages/85/00/3905332b6dc3cd3f1d9921d64b6a6a80dc96938624389c25f960b58333ad/tamnun-0.1.1-py3-none-any.whl\n",
      "Collecting numpy==1.15.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/7f/9d804d2348471c67a7d8b5f84f9bc59fd1cefa148986f2b74552f8573555/numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
      "\u001b[K     |████████████████████████████████| 13.9MB 237kB/s \n",
      "\u001b[?25hCollecting torch==1.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/60/f685fb2cfb3088736bafbc9bdbb455327bdc8906b606da9c9a81bae1c81e/torch-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (676.9MB)\n",
      "\u001b[K     |████████████████████████████████| 676.9MB 15kB/s \n",
      "\u001b[?25hCollecting scikit-learn==0.20.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/3a/b92670f5c368c20329ecc4c255993fae7934564d485c3ed7ea7b8da7f741/scikit_learn-0.20.2-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
      "\u001b[K     |████████████████████████████████| 5.4MB 13.8MB/s \n",
      "\u001b[?25hCollecting pytorch-transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 59.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.2->tamnun) (1.4.1)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 41.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->tamnun) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 48.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->tamnun) (1.14.48)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->tamnun) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->tamnun) (4.41.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers->tamnun) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers->tamnun) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers->tamnun) (0.16.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers->tamnun) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers->tamnun) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.48 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers->tamnun) (1.17.48)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->tamnun) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->tamnun) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->tamnun) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->tamnun) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->pytorch-transformers->tamnun) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->pytorch-transformers->tamnun) (0.15.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=b80cd827ef0c263a35452ab6e7b1b4c19af04d154af31ce35bad554304171454\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: torchvision 0.7.0+cu101 has requirement torch==1.6.0, but you'll have torch 1.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.3.0 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.15.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: plotnine 0.6.0 has requirement numpy>=1.16.0, but you'll have numpy 1.15.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: astropy 4.0.1.post1 has requirement numpy>=1.16, but you'll have numpy 1.15.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, torch, scikit-learn, sentencepiece, sacremoses, pytorch-transformers, tamnun\n",
      "  Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "  Found existing installation: torch 1.6.0+cu101\n",
      "    Uninstalling torch-1.6.0+cu101:\n",
      "      Successfully uninstalled torch-1.6.0+cu101\n",
      "  Found existing installation: scikit-learn 0.22.2.post1\n",
      "    Uninstalling scikit-learn-0.22.2.post1:\n",
      "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
      "Successfully installed numpy-1.15.4 pytorch-transformers-1.2.0 sacremoses-0.0.43 scikit-learn-0.20.2 sentencepiece-0.1.91 tamnun-0.1.1 torch-1.1.0\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "QqnQrnCsaF_n",
    "colab": {}
   },
   "source": [
    "import tamnun"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "rxwVf8yba7rq",
    "colab": {}
   },
   "source": [
    "import codecs\n",
    "import re\n",
    "import numpy as np\n",
    "from tamnun.bert import BertVectorizer, BertClassifier\n",
    "import pandas as pd"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t0gSXCknTaUl",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K895Tc1RxC9v",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "outputId": "13cf73df-93a4-4c49-c5c4-da8708d3cbad"
   },
   "source": [
    "from google.colab import files\n",
    "import io\n",
    "uploaded = files.upload()\n",
    "temp = pd.read_csv(io.BytesIO(uploaded['sentences_list_shuffled_tagged_topics_2_train.csv']))\n",
    "data = temp['text']\n",
    "tags = temp['sentiment_tag'] + 1\n",
    "data.shape, tags.shape\n"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-685434c2-9279-4fd9-ada2-91baec57743f\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-685434c2-9279-4fd9-ada2-91baec57743f\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "error",
     "ename": "MessageError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a04e1c03f3be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentences_list_shuffled_tagged_topics_2_train.csv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMessageError\u001b[0m: TypeError: Cannot read property '_uploadFiles' of undefined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z6UwIT4MTN37",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def run_bert(train_tokens, train_tags, test_tokens, test_tags):\n",
    "  vectorizer = BertVectorizer(do_truncate=True, bert_model='bert-base-multilingual-cased').fit(train_tokens)\n",
    "  train_X = vectorizer.transform(train_tokens)\n",
    "  clf = BertClassifier(num_of_classes=3, bert_model_name='bert-base-multilingual-cased', lr=1e-5).fit(train_X, train_tags)\n",
    "  test_X = vectorizer.transform(test_tokens)\n",
    "  predicted = clf.predict(test_X)\n",
    "  accuracy = accuracy_score(test_tags, predicted)\n",
    "  print(confusion_matrix(test_tags, predicted))\n",
    "  return accuracy\n"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rqdNssCkoiR8",
    "colab_type": "code",
    "colab": {
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "ok": true,
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "status": 200,
       "status_text": ""
      }
     },
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "outputId": "c768e1b6-ff04-4bf8-a91a-bbe27e6f27d0"
   },
   "source": [
    "uploaded = files.upload()\n",
    "temp = pd.read_csv(io.BytesIO(uploaded['sentences_list_shuffled_tagged_topics_2_test.csv']))\n",
    "data_test = temp['text']\n",
    "run_bert(data, tags, data_test, None)"
   ],
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-dd2b2d36-bf11-4d91-aa2e-46e8f25e1d20\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-dd2b2d36-bf11-4d91-aa2e-46e8f25e1d20\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "Saving sentences_list_shuffled_tagged_topics_2_test.csv to sentences_list_shuffled_tagged_topics_2_test (3).csv\n",
      "Epoch 1/5:\n",
      "77/78 batch loss: 0.6633488535881042 avg loss: 0.9997237569246537\n",
      "Epoch 2/5:\n",
      "77/78 batch loss: 0.472657710313797 avg loss: 0.9066177197755911\n",
      "Epoch 3/5:\n",
      "77/78 batch loss: 1.0919427871704102 avg loss: 0.7899028326456363\n",
      "Epoch 4/5:\n",
      "77/78 batch loss: 0.788998544216156 avg loss: 0.6716975884941908\n",
      "Epoch 5/5:\n",
      "77/78 batch loss: 0.18956363201141357 avg loss: 0.5522281174094249\n",
      "['0, ', '1, ', '1, ', '0, ', '0, ', '1, ', '1, ', '0, ', '0, ', '1, ', '0, ', '0, ', '1, ', '1, ', '0, ', '0, ', '0, ', '0, ', '1, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '1, ', '0, ', '1, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '1, ', '1, ', '0, ', '0, ', '1, ', '0, ', '0, ', '0, ', '1, ', '0, ', '0, ', '0, ', '1, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '1, ', '0, ', '2, ', '0, ', '1, ', '0, ', '2, ', '0, ', '0, ', '1, ', '0, ', '0, ', '1, ', '0, ', '0, ', '0, ', '1, ', '0, ', '1, ', '1, ', '0, ', '1, ', '0, ', '1, ', '1, ', '0, ', '0, ', '1, ', '1, ', '0, ', '1, ', '0, ', '0, ', '0, ', '0, ', '0, ', '0, ', '1, ', '0, ', '1, ', '0, ', '1, ', '1, ', '1, ', '0, ', '0, ', '0, ', '1, ', '1, ', '0, ', '1, ', '1, ', '1, ', '0, ', '0, ', '0, ', '0, ', '0, ', '1, ', '0, ', '1, ']\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_CvLxWanvmRc",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "e1cc6004-d46f-4a57-abe5-61f7a95437d0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "TRAIN_SIZE = len(data)\n",
    "n_folds = 10\n",
    "def get_folds(X_train, y_train, num_folds=n_folds):\n",
    "    fold_size = int(TRAIN_SIZE / num_folds)\n",
    "    fold_idx = np.arange(fold_size, TRAIN_SIZE, fold_size)\n",
    "    folds_X = []\n",
    "    folds_y = []\n",
    "    cur = 0\n",
    "    for i in fold_idx:\n",
    "        folds_X.append(X_train[cur:i])\n",
    "        folds_y.append(y_train[cur:i])\n",
    "        cur = i\n",
    "    folds_X.append(X_train[cur:])\n",
    "    folds_y.append(y_train[cur:])\n",
    "    return np.array(folds_X), np.array(folds_y)\n",
    "\n",
    "def CV(data, tags):\n",
    "    folds_X, folds_y = get_folds(data, tags)\n",
    "    mask = np.ones(len(folds_X), dtype=bool)\n",
    "    accuracies = []\n",
    "    for j in range(n_folds):\n",
    "        mask[j] = False\n",
    "        cur_X_train = np.concatenate(folds_X[mask])\n",
    "        cur_y_train = np.concatenate(folds_y[mask])\n",
    "        cur_X_test = folds_X[j]\n",
    "        cur_y_test = folds_y[j]\n",
    "        print(data.shape, cur_X_train.shape, cur_X_test.shape)\n",
    "        mask[j] = True\n",
    "        accuracy = run_bert(cur_X_train, cur_y_train, cur_X_test, cur_y_test)\n",
    "        accuracies.append(accuracy)\n",
    "    print('accuracies', accuracies)\n",
    "    print('accuracy', np.average(accuracies))\n",
    "\n",
    "CV(data, tags)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "(314,) (283,) (31,)\n",
      "Epoch 1/5:\n",
      "70/71 batch loss: 0.8868464827537537 avg loss: 1.0261794941526063\n",
      "Epoch 2/5:\n",
      "70/71 batch loss: 0.9861459732055664 avg loss: 0.9750136674289972\n",
      "Epoch 3/5:\n",
      "70/71 batch loss: 1.3153938055038452 avg loss: 0.9006314781350149\n",
      "Epoch 4/5:\n",
      "70/71 batch loss: 0.9713189005851746 avg loss: 0.8391823944911151\n",
      "Epoch 5/5:\n",
      "70/71 batch loss: 0.09171418100595474 avg loss: 0.6633995340113908\n",
      "[[ 2  2  1]\n",
      " [ 1  7  1]\n",
      " [ 0  7 10]]\n",
      "(314,) (283,) (31,)\n",
      "Epoch 1/5:\n",
      "70/71 batch loss: 1.3881889581680298 avg loss: 1.0450740851147073\n",
      "Epoch 2/5:\n",
      "70/71 batch loss: 0.9396035671234131 avg loss: 0.9724878475699626\n",
      "Epoch 3/5:\n",
      "70/71 batch loss: 0.8754212260246277 avg loss: 0.8407854085237207\n",
      "Epoch 4/5:\n",
      "70/71 batch loss: 0.4300800561904907 avg loss: 0.6793962882857927\n",
      "Epoch 5/5:\n",
      "70/71 batch loss: 0.6534706354141235 avg loss: 0.5089660268014585\n",
      "[[ 1  0  3]\n",
      " [ 3  4  6]\n",
      " [ 2  0 12]]\n",
      "(314,) (283,) (31,)\n",
      "Epoch 1/5:\n",
      "70/71 batch loss: 1.105623722076416 avg loss: 1.0205140676296933\n",
      "Epoch 2/5:\n",
      "70/71 batch loss: 1.1864709854125977 avg loss: 1.0093440564585403\n",
      "Epoch 3/5:\n",
      "70/71 batch loss: 1.0320967435836792 avg loss: 1.0027390634509878\n",
      "Epoch 4/5:\n",
      "70/71 batch loss: 0.9444763660430908 avg loss: 0.9419209528976763\n",
      "Epoch 5/5:\n",
      "70/71 batch loss: 0.5356800556182861 avg loss: 0.7610449299845897\n",
      "[[ 1  4  1]\n",
      " [ 0 10  3]\n",
      " [ 0  1 11]]\n",
      "(314,) (283,) (31,)\n",
      "Epoch 1/5:\n",
      "70/71 batch loss: 1.0244718790054321 avg loss: 1.0219860379125032\n",
      "Epoch 2/5:\n",
      "70/71 batch loss: 1.0066829919815063 avg loss: 0.9846693806245294\n",
      "Epoch 3/5:\n",
      "70/71 batch loss: 0.3743429481983185 avg loss: 0.8999677938474736\n",
      "Epoch 4/5:\n",
      "70/71 batch loss: 0.5032568573951721 avg loss: 0.7256181617857704\n",
      "Epoch 5/5:\n",
      "70/71 batch loss: 0.34256160259246826 avg loss: 0.5940403130272744\n",
      "[[ 7  0  1]\n",
      " [ 0  6  2]\n",
      " [ 1  3 11]]\n",
      "(314,) (283,) (31,)\n",
      "Epoch 1/5:\n",
      "70/71 batch loss: 1.1706804037094116 avg loss: 1.0526334072502566\n",
      "Epoch 2/5:\n",
      "70/71 batch loss: 0.988043487071991 avg loss: 0.9940497405092481\n",
      "Epoch 3/5:\n",
      "70/71 batch loss: 0.2732527554035187 avg loss: 0.8611441787699579\n",
      "Epoch 4/5:\n",
      "70/71 batch loss: 0.38170623779296875 avg loss: 0.6523709878535338\n",
      "Epoch 5/5:\n",
      "70/71 batch loss: 0.1213018074631691 avg loss: 0.47123299696495835\n",
      "[[1 1 2]\n",
      " [0 9 3]\n",
      " [1 5 9]]\n",
      "(314,) (283,) (31,)\n",
      "Epoch 1/5:\n",
      "70/71 batch loss: 0.6008976101875305 avg loss: 1.0459387990790354\n",
      "Epoch 2/5:\n",
      "70/71 batch loss: 1.1450169086456299 avg loss: 0.9625027104162834\n",
      "Epoch 3/5:\n",
      "70/71 batch loss: 0.6106920838356018 avg loss: 0.825074487169024\n",
      "Epoch 4/5:\n",
      "70/71 batch loss: 1.052597999572754 avg loss: 0.6028263247768644\n",
      "Epoch 5/5:\n",
      "70/71 batch loss: 0.45698317885398865 avg loss: 0.43377465282527494\n",
      "[[ 1  4  1]\n",
      " [ 1  4  1]\n",
      " [ 2  6 11]]\n",
      "(314,) (283,) (31,)\n",
      "Epoch 1/5:\n",
      "70/71 batch loss: 0.9446006417274475 avg loss: 1.0563698419382874\n",
      "Epoch 2/5:\n",
      "70/71 batch loss: 0.9039233326911926 avg loss: 0.9919520482211046\n",
      "Epoch 3/5:\n",
      "70/71 batch loss: 0.7327279448509216 avg loss: 0.9002914890437059\n",
      "Epoch 4/5:\n",
      "70/71 batch loss: 0.20213620364665985 avg loss: 0.7277418868222707\n",
      "Epoch 5/5:\n",
      "70/71 batch loss: 0.29281654953956604 avg loss: 0.4484542501224598\n",
      "[[ 0  4  1]\n",
      " [ 1 10  1]\n",
      " [ 1  5  8]]\n",
      "(314,) (283,) (31,)\n",
      "Epoch 1/5:\n",
      "70/71 batch loss: 1.0121344327926636 avg loss: 1.0590888731916186\n",
      "Epoch 2/5:\n",
      "70/71 batch loss: 0.6133259534835815 avg loss: 0.9491245796982671\n",
      "Epoch 3/5:\n",
      "70/71 batch loss: 0.6866841316223145 avg loss: 0.79940087148841\n",
      "Epoch 4/5:\n",
      "70/71 batch loss: 0.9212613105773926 avg loss: 0.6077450954578292\n",
      "Epoch 5/5:\n",
      "70/71 batch loss: 0.05369603633880615 avg loss: 0.38716727851981847\n",
      "[[ 1  1  1]\n",
      " [ 3  5  7]\n",
      " [ 1  1 11]]\n",
      "(314,) (283,) (31,)\n",
      "Epoch 1/5:\n",
      "70/71 batch loss: 0.7685944437980652 avg loss: 1.035622582469188\n",
      "Epoch 2/5:\n",
      "70/71 batch loss: 1.1626108884811401 avg loss: 0.9921443092990929\n",
      "Epoch 3/5:\n",
      "70/71 batch loss: 0.7294950485229492 avg loss: 0.8984578688379744\n",
      "Epoch 4/5:\n",
      "70/71 batch loss: 0.7832889556884766 avg loss: 0.699699460830487\n",
      "Epoch 5/5:\n",
      "70/71 batch loss: 1.028327465057373 avg loss: 0.4511418344689087\n",
      "[[ 3  1  2]\n",
      " [ 2  2  4]\n",
      " [ 2  0 15]]\n",
      "(314,) (283,) (31,)\n",
      "Epoch 1/5:\n",
      "70/71 batch loss: 1.1736239194869995 avg loss: 1.0372078746137485\n",
      "Epoch 2/5:\n",
      "70/71 batch loss: 0.7497382164001465 avg loss: 0.9865969797255287\n",
      "Epoch 3/5:\n",
      "70/71 batch loss: 1.2697221040725708 avg loss: 0.8789978707340401\n",
      "Epoch 4/5:\n",
      "70/71 batch loss: 0.9114036560058594 avg loss: 0.6801792683315949\n",
      "Epoch 5/5:\n",
      "70/71 batch loss: 0.29156580567359924 avg loss: 0.49162432194595607\n",
      "[[ 5  2  1]\n",
      " [ 0  6  2]\n",
      " [ 1  2 12]]\n",
      "accuracies [0.6129032258064516, 0.5483870967741935, 0.7096774193548387, 0.7741935483870968, 0.6129032258064516, 0.5161290322580645, 0.5806451612903226, 0.5483870967741935, 0.6451612903225806, 0.7419354838709677]\n",
      "accuracy 0.6290322580645161\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}